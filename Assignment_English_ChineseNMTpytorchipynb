{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "_Z-N7Ylp0-Gi",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "b0ce13b5ea561fdc64db96b3016ced66",
          "grade": false,
          "grade_id": "cell-5c7c35e5db56651f",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# Machine Translation using Sequence to Sequence LSTM networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "7BEzkQrJ0-Gn",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "c09f58dd19c22fd8c14a82ecfdb3ad36",
          "grade": false,
          "grade_id": "cell-86a6d09c34d33f25",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Machine translation refers to the use of machines or software to translate text to speech or speech from one language to another language.\n",
        "\n",
        "In this assignment we will work out the demonstration of how we can apply the LSTM networks to translate speech from one language to another.\n",
        "\n",
        "We will be translating sequences from English to Chinese."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "pGuEgkXT0-Gn",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "aaf14ad60b6057ae5ef2f283fae3a801",
          "grade": false,
          "grade_id": "cell-e29498e719ab95c6",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## Datasets\n",
        "We will be using this dataset. https://www.manythings.org/anki/cmn-eng.zip.\n",
        "\n",
        "Few samples of the dataset looks as follows:\n",
        "\n",
        "**$ENGLISH \\hspace{10mm} CHINESE$**\n",
        "\n",
        "$Go. \\hspace{30mm} 走 $\n",
        "\n",
        "$Run! \\hspace{30mm} 跑!$\n",
        "\n",
        "$Fire! \\hspace{30mm} A火！$\n",
        "\n",
        "$Help! \\hspace{30mm} 救命!$\n",
        "\n",
        "$Jump. \\hspace{30mm} 跳.$\n",
        "\n",
        "$Stop! \\hspace{30mm} 停止!$\n",
        "\n",
        "We can see that on the left column, we have a list of english sequences like, GO, RUN, FIRE, HELP, etc and on the right we have their respective CHINESE tranlsations.\n",
        "\n",
        "Here, the input to the model will be the list of English sentences and the target will be the list of Chinese translations.\n",
        "\n",
        "Here in the dataset,\n",
        "\n",
        "We will follow the following steps duing the machine translation:\n",
        "\n",
        "1. Preprocess the training sequenes\n",
        "2. Develop sequence to sequence LSTM model\n",
        "3. Train LSTM model\n",
        "4. Evalute model by testing the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "AxGshOMk6_n9",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "7fc6f0c2167c4587dc68f0dcbeeac76e",
          "grade": false,
          "grade_id": "cell-322635f771076732",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Importing necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "ZCo5hAFPw6MR",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "453a2c02cdbbb02cb0046e352998d837",
          "grade": false,
          "grade_id": "cell-92d78258255f0c3e",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "UrdGrSJoxC3o",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "fe69062cf677017d2c47b789df0f9a32",
          "grade": false,
          "grade_id": "cell-64ea11783dd9398f",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "vU1L7fAckbxe",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "ca7a41a47f2a4f4c921145cb562375bc",
          "grade": false,
          "grade_id": "cell-949aff3298d2f0f0",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Let's read the dataset from the directory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "mQgGzF147E-j",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "56425b9d799dd5ce1268301ab7c58c7e",
          "grade": false,
          "grade_id": "cell-f81b84edf1b80a87",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Reading the datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "9VCyVeGew6MT",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "fcc930cecb546092836f694d5b4ce982",
          "grade": false,
          "grade_id": "cell-3cdcf87702aba82a",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "fc6a5b16-82c8-4969-965a-63c7fba8293a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     eng             chin  \\\n",
              "0                                    Hi.               嗨。   \n",
              "1                                    Hi.              你好。   \n",
              "2                                   Run.            你用跑的。   \n",
              "3                                  Wait!              等等！   \n",
              "4                                  Wait!             等一下！   \n",
              "...                                  ...              ...   \n",
              "15852  When did she promise to meet him?         她答应几时见他？   \n",
              "15853  When did you change your address?    你什麼時候更改了你的地址?   \n",
              "15854  When did your baby start talking?  你的寶寶，什麼時候開始說話的？   \n",
              "15855  When was this university founded?     这所大学是什么时候建的？   \n",
              "15856  Where are you going to eat lunch?        你要去哪裡吃午飯？   \n",
              "\n",
              "                                                    info  \n",
              "0      CC-BY 2.0 (France) Attribution: tatoeba.org #5...  \n",
              "1      CC-BY 2.0 (France) Attribution: tatoeba.org #5...  \n",
              "2      CC-BY 2.0 (France) Attribution: tatoeba.org #4...  \n",
              "3      CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
              "4      CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
              "...                                                  ...  \n",
              "15852  CC-BY 2.0 (France) Attribution: tatoeba.org #3...  \n",
              "15853  CC-BY 2.0 (France) Attribution: tatoeba.org #6...  \n",
              "15854  CC-BY 2.0 (France) Attribution: tatoeba.org #3...  \n",
              "15855  CC-BY 2.0 (France) Attribution: tatoeba.org #5...  \n",
              "15856             CC-BY 2.0 (France) Attribution: tatoeb  \n",
              "\n",
              "[15857 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4a2593ec-9a12-4ac6-9004-15f8e5125432\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>chin</th>\n",
              "      <th>info</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>嗨。</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>你好。</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Run.</td>\n",
              "      <td>你用跑的。</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Wait!</td>\n",
              "      <td>等等！</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Wait!</td>\n",
              "      <td>等一下！</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15852</th>\n",
              "      <td>When did she promise to meet him?</td>\n",
              "      <td>她答应几时见他？</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15853</th>\n",
              "      <td>When did you change your address?</td>\n",
              "      <td>你什麼時候更改了你的地址?</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15854</th>\n",
              "      <td>When did your baby start talking?</td>\n",
              "      <td>你的寶寶，什麼時候開始說話的？</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15855</th>\n",
              "      <td>When was this university founded?</td>\n",
              "      <td>这所大学是什么时候建的？</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15856</th>\n",
              "      <td>Where are you going to eat lunch?</td>\n",
              "      <td>你要去哪裡吃午飯？</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeb</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15857 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a2593ec-9a12-4ac6-9004-15f8e5125432')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4a2593ec-9a12-4ac6-9004-15f8e5125432 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4a2593ec-9a12-4ac6-9004-15f8e5125432');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# lines = pd.read_table('/content/drive/My Drive/NMT_Assignment_Fuse/cmn.txt', names=['eng', 'chin', 'info'])\n",
        "lines = pd.read_table('./cmn.txt', names=['eng', 'chin', 'info'])\n",
        "lines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "dvqLeT1hkS_1",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "4602bba070f00465a7f411ce333ea381",
          "grade": false,
          "grade_id": "cell-109bf8e6353d477b",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "We are concerned with only english to chinese translation, so we choose these two columns.\n",
        "### Exercise 1\n",
        "#### Task 1\n",
        "<b><div style=\"text-align: right\">[POINTS: 2]</div></b>\n",
        "* Select the English and Chinese translation columns\n",
        "* Select the first 10,000 samples and store it on `lines` "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "deletable": false,
        "id": "txXegvQykUFr",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "11a7c082ad344bbf53fbc79a134ca6a5",
          "grade": false,
          "grade_id": "cell-8d554e7a8fae2b5f",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "tags": [
          "Ex-1-Task-1"
        ]
      },
      "outputs": [],
      "source": [
        "### Ex-1-Task-1\n",
        "# lines = None\n",
        "\n",
        "# Select `eng` and `chin` columns from the table\n",
        "# take only first 10,000 samples to train\n",
        "\n",
        "### BEGIN SOLUTION\n",
        "lines = lines[['eng', 'chin']][:10000]\n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "zgYFaXI_0-Gr",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a3d1a3f4c8d47e319282102289d91b29",
          "grade": true,
          "grade_id": "cell-cc75ee800e422bec",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false
        },
        "tags": [
          "Ex-1-Task-1"
        ]
      },
      "outputs": [],
      "source": [
        "assert lines is not None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Kh7IpJH-w6MT",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "5bd3454c7013d5e967f924cdf40bec69",
          "grade": false,
          "grade_id": "cell-c1a557d4e1f790be",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f3fc637-90f8-4dbf-9581-d85103f9685e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# displaying shape of the training set\n",
        "lines.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "qJqfTx_S7MBm",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "6a3fefeb3dbff03a8151d1ceafe32a43",
          "grade": false,
          "grade_id": "cell-6f124aca6532ebf9",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Data-Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "1p_OI3gCm1nY",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "69ae6492cb816a54dd76e1158feb7ff8",
          "grade": false,
          "grade_id": "cell-12b91bc6ebf516bb",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "We will follow the following preprocessing steps in order to clean the dataset and fit into model training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "9OavBlnl0-Gs",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "d0e3ec6a0dcb40c939ed480e66929e06",
          "grade": false,
          "grade_id": "cell-55d8579a96347262",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "#### Lowercasing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "ayVesOcK0-Gs",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a573be3cc12561afab4c01b19ce01795",
          "grade": false,
          "grade_id": "cell-818a7628e07222c7",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# lowercase inputs on the columns \n",
        "lines.eng = lines.eng.apply(lambda x: x.lower())\n",
        "lines.chin = lines.chin.apply(lambda x: x.lower())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "ePdmVLLlw6MU",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "82f8bf7c2439c84eb248d1b09d073edf",
          "grade": false,
          "grade_id": "cell-ae96a6b81a1185d7",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Exercise 2\n",
        "\n",
        "Above, we just performed lowercasing of the input samples. Lowercasing is the first operation we performed. Now, we will perform other operations like: `Removing Quotes`, `Removing Special Characters`, `Removing Uneven Spaces`, `Adding <START> and <END> tokens`, etc. Perform similar implementations like that mentioned above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "d-vf6AbR0-Gs",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "068af81cad8ab07cbbceb9a3cbccd94d",
          "grade": false,
          "grade_id": "cell-88c2f1ffb428de99",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "#### Removing Quotes\n",
        "<b><div style=\"text-align: right\">[POINTS: 3]</div></b>\n",
        "#### Task 1\n",
        "<b><div style=\"text-align: right\">[POINTS: 1]</div></b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "deletable": false,
        "id": "cnxN3CNhw6MU",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "24f6e9de968fb417c8bddc9654cbe58b",
          "grade": false,
          "grade_id": "cell-166a4b682ff40791",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "tags": [
          "Ex-2-Task-1"
        ]
      },
      "outputs": [],
      "source": [
        "### Ex-2-Task-1\n",
        "\n",
        "# remove all the quotes \"'\" from the columns\n",
        "\n",
        "# lines.eng = None\n",
        "# lines.chin = None\n",
        "\n",
        "# Exercise 2 | Task 1\n",
        "### BEGIN SOLUTION\n",
        "lines.eng = lines.eng.apply(lambda x: x.replace(\"\\'\", \"\"))\n",
        "lines.chin = lines.chin.apply(lambda x: x.replace(\"\\'\", \"\"))\n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "EFKIDmSg0-Gt",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "8533a681c6890484e1bd4547c9a4380a",
          "grade": true,
          "grade_id": "cell-71fafecfa7e89a02",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false
        },
        "tags": [
          "Ex-2-Task-1"
        ]
      },
      "outputs": [],
      "source": [
        "assert lines.eng is not None\n",
        "assert lines.chin is not None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "dQPsCJ-t0-Gt",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "fe5f76d98ab6f1851b1222a619d68c5c",
          "grade": false,
          "grade_id": "cell-17278651b7e58ab4",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "#### Removing Special Characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "3c7SFZZJw6MU",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1500be7e854dc4d11e9ab8ce40c44f4a",
          "grade": false,
          "grade_id": "cell-57bd2575631fb4c8",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# Set of all special characters\n",
        "sets_of_punctuations = set(string.punctuation)\n",
        "\n",
        "# Removing sets of all special characters from the inputs\n",
        "lines.eng = lines.eng.apply(lambda x: ''.join(char for char in x if char not in sets_of_punctuations))\n",
        "lines.chin = lines.chin.apply(lambda x: ''.join(char for char in x if char not in sets_of_punctuations))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "zdfLmsrY0-Gt",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "7e6b1f4a051d2cb789b504fb6beb0685",
          "grade": false,
          "grade_id": "cell-5ae1b11f41d71b27",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "#### Removing Uneven Spaces\n",
        "#### Task 2\n",
        "<b><div style=\"text-align: right\">[POINTS: 1]</div></b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "deletable": false,
        "id": "0NJg9Wtxw6MV",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "6262580c52c9c0d41e3f48056d849424",
          "grade": false,
          "grade_id": "cell-b5bd2c20a73d1679",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "tags": [
          "Ex-2-Task-2"
        ]
      },
      "outputs": [],
      "source": [
        "### Ex-2-Task-2\n",
        "# lines.eng = None\n",
        "# lines.chin = None\n",
        "\n",
        "# There may be uneven spaces in the inputs\n",
        "# We have to remove the extra spaces too\n",
        "\n",
        "# Exercise 2 | Task 2\n",
        "### BEGIN SOLUTION\n",
        "lines.eng = lines.eng.apply(lambda x: \" \".join(word for word in x.split()))\n",
        "lines.chin = lines.chin.apply(lambda x: \" \".join(word for word in x.split()))\n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "M4dMDkYn0-Gu",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "9274c3da54ce529a0a48fd322b407e24",
          "grade": true,
          "grade_id": "cell-557c50952c53e7ed",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false
        },
        "tags": [
          "Ex-2-Task-2"
        ]
      },
      "outputs": [],
      "source": [
        "assert lines.eng is not None\n",
        "assert lines.chin is not None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "nf_nMZp00-Gu",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "50e043f4e44d400cb3a775b965b6b665",
          "grade": false,
          "grade_id": "cell-03607f2602068f04",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "#### Adding `<START>` and `<END>` Tokens\n",
        "E.g.\n",
        "'Hi' = '`<START>` Hi `<END>`'\n",
        "#### Task 3\n",
        "<b><div style=\"text-align: right\">[POINTS: 1]</div></b>\n",
        "We will perform this operations over Chinese column samples only because we are converting English sequences to chinese only for now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "deletable": false,
        "id": "24kKSFCjw6MW",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d8df2bf22b3b379332eeeebc57bd287e",
          "grade": false,
          "grade_id": "cell-ad1abc3f8ffea62a",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "tags": [
          "Ex-2-Task-3"
        ]
      },
      "outputs": [],
      "source": [
        "### Ex-2-Task-3\n",
        "# lines.chin = None\n",
        "\n",
        "# Adding <START> and <END> tokens with trailing spaces\n",
        "\n",
        "# Exercise 2 | Task 3\n",
        "### BEGIN SOLUTION\n",
        "lines.chin = lines.chin.apply(lambda x: f\"<START> {x} <END>\")\n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "PJA33kQZ0-Gu",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "9a0a377fd98f6659655db1b424338212",
          "grade": true,
          "grade_id": "cell-fd254802897335ea",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false
        },
        "tags": [
          "Ex-2-Task-3"
        ]
      },
      "outputs": [],
      "source": [
        "assert lines.chin is not None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "ojnbyezHqUaG",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "86a9ff8785d8ef6fb2437aae08cf171b",
          "grade": false,
          "grade_id": "cell-d4bdec9ded84970b",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Now, our next task is to create a list of vocabularies of English and Chinese Inputs.\n",
        "\n",
        "Following code will tokenize the words present in the English and Chinese dataset that we use to train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "vBibz4Gn666N",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "8153db3e15c212af999f9d8622e21efc",
          "grade": false,
          "grade_id": "cell-fd22ab95a6103221",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Tokenizing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "5GtJWhtG7UiM",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "31a8e3c3129bf64cf3af93c2d1e27ca2",
          "grade": false,
          "grade_id": "cell-3c2d3a9eb7586ce1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Tokenizing the English and the Chinese words in to set `all_english_vocabs` and `all_chinese_vocabs`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "dY-j6xPpqdPT",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "eb09fd0d0113e567e720dff6a2d57257",
          "grade": false,
          "grade_id": "cell-cdb536778da0a35b",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# Collect English Vocabs\n",
        "all_english_vocabs = set()\n",
        "for english in lines.eng:\n",
        "    words = english.split()\n",
        "    for word in words:\n",
        "        if word not in all_english_vocabs:\n",
        "            all_english_vocabs.add(word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "UJGtunRdtPdX",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2c81f85aa3a4cd2c1d99800f0a4bfe4b",
          "grade": false,
          "grade_id": "cell-9573d55a6cc7a79a",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# Collect Chinese Vocabs\n",
        "all_chinese_vocabs = set()\n",
        "for chinese in lines.chin:\n",
        "    words = chinese.split()\n",
        "    for word in words:\n",
        "        if word not in all_chinese_vocabs:\n",
        "            all_chinese_vocabs.add(word)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "AqQxd93At8Y_",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "aaa117a1a9ef6101a6dcbb4e172ff64c",
          "grade": false,
          "grade_id": "cell-2b285bbaaf0bb29c",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Let's implement the following codes to find the maximum sequence length of input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "ApMcilUdw6MX",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "8406af3f5b0446b0750be37157760ddf",
          "grade": false,
          "grade_id": "cell-54947cadd4bdeb58",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "dfd76e45-c035-49cb-f671-482d08285bb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        }
      ],
      "source": [
        "# Max Length of input sequence\n",
        "sequence_length = []\n",
        "for line in lines.eng:\n",
        "    sequence_length.append(len(line.split(' ')))\n",
        "max_length_inp = np.max(sequence_length)\n",
        "print(max_length_inp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "5r8H-xriw6MX",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "bb4f46c3196a78a0d7abba9159251659",
          "grade": false,
          "grade_id": "cell-389126c8d63c4124",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "4767eea8-f47d-4cc7-da86-357af37b6a3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Max Length of target sequence\n",
        "sequence_length = []\n",
        "for line in lines.chin:\n",
        "    sequence_length.append(len(line.split(' ')))\n",
        "max_length_targ = np.max(sequence_length)\n",
        "max_length_targ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "z2ID7e3a0-Gw",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "94d6bac02b2788a4fe011e9d500c21a4",
          "grade": false,
          "grade_id": "cell-8f6c8ab252764056",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "With this, we can see that the maximum input sequence is 8 and the maximum target sequence is 5."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "scApqmY00-Gw",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "40d5094d209e6b7975b5e3eca73db2a9",
          "grade": false,
          "grade_id": "cell-05bfb2e9b479f1e7",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Exercise 3\n",
        "<b><div style=\"text-align: right\">[POINTS: 2]</div></b>\n",
        "#### Task 1\n",
        "<b><div style=\"text-align: right\">[POINTS: 1]</div></b>\n",
        "Sort and store the tokenized English and Chinese words on the variables `input_words` and `target_words`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "deletable": false,
        "id": "mTOotq_Iw6MY",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "9078779aa366ba1983eafb52d994367c",
          "grade": false,
          "grade_id": "cell-a233cc05cff264ec",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "tags": [
          "Ex-3-Task-1"
        ]
      },
      "outputs": [],
      "source": [
        "### Ex-3-Task-1\n",
        "\n",
        "# input_words = None\n",
        "# target_words = None\n",
        "\n",
        "# Sorting and Storing the tokens of English and Chinese words\n",
        "\n",
        "# Exercise 3\n",
        "### BEGIN SOLUTION\n",
        "input_words = sorted(all_english_vocabs)\n",
        "target_words = sorted(all_chinese_vocabs)\n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "e9MTr3c-0-Gx",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "7dc42d6bc240ed9b4598a698272bdbae",
          "grade": true,
          "grade_id": "cell-15b8c56f73279370",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false
        },
        "tags": [
          "Ex-3-Task-1"
        ]
      },
      "outputs": [],
      "source": [
        "assert input_words is not None\n",
        "assert target_words is not None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlODcVXyAo98"
      },
      "source": [
        "#### Task 2\n",
        "<b><div style=\"text-align: right\">[POINTS: 1]</div></b>\n",
        "Since, we are performing Machine translation, we have an encoder and decoder kind of architecture. We will have the encoder architecture as following:\n",
        "\n",
        "<div align=\"center\">\n",
        "<figure>\n",
        "<img src=\"https://doc.google.com/a/fusemachines.com/uc?id=1voHxN0hllGSLfyPJSy6tI_hzTNO6hHRl\" >\n",
        "<figcaption>Figure 1. Machine Translation\n",
        "</figcaption>\n",
        "</figure>\n",
        "</div>\n",
        "\n",
        "Here, the green denoted LSTM cells represent the encoder part and the red LSTM cells represent the decoder part of a Machine Translation network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "deletable": false,
        "id": "ZkXtWETvAnZ5",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "c9db575d6fd33f6657706244f3d78c37",
          "grade": false,
          "grade_id": "cell-d21094fc3564a7c2",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "tags": [
          "Ex-3-Task-2"
        ],
        "outputId": "f5c82c57-7351-4318-b29c-3cfe6e2831e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3380 9023\n"
          ]
        }
      ],
      "source": [
        "### Ex-3-Task-2\n",
        "# counting the total tokens of English and Chinese words\n",
        "num_encoder_tokens = None\n",
        "num_decoder_tokens = None\n",
        "### BEGIN SOLUTION\n",
        "num_encoder_tokens = len(input_words)\n",
        "num_decoder_tokens = len(target_words)\n",
        "### END SOLUTION\n",
        "print(num_encoder_tokens, num_decoder_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "idi_diAO0-Gx",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ede6a6c888773ecf37e16e8e132e6643",
          "grade": true,
          "grade_id": "cell-cd48ce4fc6942143",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false
        },
        "tags": [
          "Ex-3-Task-2"
        ]
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "HZSC0tsow6MY",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "be0bb5f1bd433ae49ce0865a36b5d4a3",
          "grade": false,
          "grade_id": "cell-040c48796e20c48e",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "aa6be90f-e8b2-41fe-a1ce-f3cf87d39705",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3381, 9024)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# For zero padding we add one extra token\n",
        "num_decoder_tokens += 1\n",
        "num_encoder_tokens += 1\n",
        "num_encoder_tokens, num_decoder_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "MYPMZqntw6MZ",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "7f9b24c88907af9d6fc4abfd0f2d3b26",
          "grade": false,
          "grade_id": "cell-df7be80213612242",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# compute and store the tokens with index in dictionary as word, index format\n",
        "input_token_index = dict([(word, i + 1) for i, word in enumerate(input_words)])\n",
        "target_token_index = dict([(word, i + 1) for i, word in enumerate(target_words)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "ofUESFVWw6MZ",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "fe1c30203bafa9868d0d233747ebf40a",
          "grade": false,
          "grade_id": "cell-85cd917cd9596b95",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# compute and store the tokens with index in dictionary as index, word format\n",
        "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "A-jl8mSpw6MZ",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "7f4b730ef6492fbd05ede8bffededdea",
          "grade": false,
          "grade_id": "cell-75e847bed23fd5e8",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "77b39360-8637-433e-aa04-ef54eaa48ee6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          eng                     chin\n",
              "6266   im dripping with sweat     <START> 我正流着汗。 <END>\n",
              "3295      he was wet all over  <START> 他从头到脚都湿了。 <END>\n",
              "2370        life is beautiful    <START> 生活是美丽的。 <END>\n",
              "1117           my dad is busy     <START> 我爸爸很忙。 <END>\n",
              "6004  have a pleasant journey      <START> 旅途愉快！ <END>"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5c03042e-4162-4767-9306-cb1b9602172b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>chin</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6266</th>\n",
              "      <td>im dripping with sweat</td>\n",
              "      <td>&lt;START&gt; 我正流着汗。 &lt;END&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3295</th>\n",
              "      <td>he was wet all over</td>\n",
              "      <td>&lt;START&gt; 他从头到脚都湿了。 &lt;END&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2370</th>\n",
              "      <td>life is beautiful</td>\n",
              "      <td>&lt;START&gt; 生活是美丽的。 &lt;END&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1117</th>\n",
              "      <td>my dad is busy</td>\n",
              "      <td>&lt;START&gt; 我爸爸很忙。 &lt;END&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6004</th>\n",
              "      <td>have a pleasant journey</td>\n",
              "      <td>&lt;START&gt; 旅途愉快！ &lt;END&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c03042e-4162-4767-9306-cb1b9602172b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5c03042e-4162-4767-9306-cb1b9602172b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5c03042e-4162-4767-9306-cb1b9602172b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# shuffling the lines to make better predictions\n",
        "lines = shuffle(lines)\n",
        "lines.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "ciFxeS0l0-Gy",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "e855f52ea26ed6a78b5271614a523804",
          "grade": false,
          "grade_id": "cell-4874858156792ac3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Train-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "U8-wDveew6Ma",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a7eedfd692c48276f98708a8a8409bcd",
          "grade": false,
          "grade_id": "cell-711ad7496e8d5a8c",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "ca5d2ce7-35d0-4d80-e09b-44037a855634",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((9000,), (1000,))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# Train - Test Split\n",
        "X, y = lines.eng, lines.chin\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)\n",
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "zSVXqHNaLirV",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "7857b81bc963cfe85ff7a67874257c74",
          "grade": false,
          "grade_id": "cell-9456558d54c0d0ea",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Following code is to generate batch of training and testing data. If you are interested in the code you can go line by line and explore the details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "kM-5q9lbw6Ma",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d776a860adbff380724704f73503def3",
          "grade": false,
          "grade_id": "cell-b1894cc022235615",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
        "    '''Function to generate a batch of data '''\n",
        "    for j in range(0, len(X), batch_size):\n",
        "        encoder_input_data = np.zeros((max_length_inp, batch_size),dtype='float32')\n",
        "        decoder_input_data = np.zeros((max_length_targ, batch_size),dtype='float32')\n",
        "        decoder_target_data = np.zeros((max_length_targ, batch_size ,num_decoder_tokens),dtype='float32')\n",
        "        for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
        "            for t, word in enumerate(input_text.split()):\n",
        "                encoder_input_data[t, i] = input_token_index[word] # encoder input seq\n",
        "            for t, word in enumerate(target_text.split()):\n",
        "                if t<len(target_text.split())-1:\n",
        "                    decoder_input_data[t, i] = target_token_index[word] # decoder input seq\n",
        "                if t>0:\n",
        "                    # decoder target sequence (one hot encoded)\n",
        "                    # does not include the START_ token\n",
        "                    # Offset by one timestep\n",
        "                    decoder_target_data[t-1, i , target_token_index[word]] = 1.\n",
        "        yield([encoder_input_data, decoder_input_data], decoder_target_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "VrCmUOPX0dsn",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "108ad531aae4affa988fcf9dbb1216f5",
          "grade": false,
          "grade_id": "cell-5ad4b7a3cc4da9e0",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# Input to the Encoder\n",
        "encoder_input_data = np.zeros((len(lines.eng), 9),dtype='float32')\n",
        "\n",
        "# output from the encoder or input to the decoder \n",
        "decoder_input_data = np.zeros((len(lines.chin), 5),dtype='float32')\n",
        "\n",
        "# output by the decoder\n",
        "decoder_target_data = np.zeros((len(lines.chin), 5, num_decoder_tokens),dtype='float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "z3QkOfY70hQK",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "8dd8a7bcec06c4a8c969cf1ef6c956b0",
          "grade": false,
          "grade_id": "cell-3c9e2cbc956e1e63",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "for i, (input_text, target_text) in enumerate(zip(lines.eng, lines.chin)):\n",
        "    for t, word in enumerate(input_text.split()):\n",
        "        encoder_input_data[i, t] = input_token_index[word]\n",
        "    for t, word in enumerate(target_text.split()):\n",
        "        decoder_input_data[i, t] = target_token_index[word]\n",
        "        if t > 0:\n",
        "            # decoder target data is ahead of decoder input by one timestep\n",
        "            decoder_target_data[i, t - 1, target_token_index[word]] = 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "aknXbSOLw6Mb",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "d1acb35327047493c41527dbd89cd048",
          "grade": false,
          "grade_id": "cell-dbc8da1b20dbba17",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Encoder - Decoder Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "7Wd_xqIbw6Mb",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "eab08df97a955b75b73b334158d24f58",
          "grade": false,
          "grade_id": "cell-6e9227c55dc44051",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "latent_dim = 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "BSPvU8Bn0-G0",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "0d20248101d130edfd111600d207cd56",
          "grade": false,
          "grade_id": "cell-906a013f79181247",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Exercise 4\n",
        "<b><div style=\"text-align: right\">[POINTS: 4]</div></b>\n",
        "#### Task 1\n",
        "<b><div style=\"text-align: right\">[POINTS: 1]</div></b>\n",
        "Store the hidden state and context vector as a result of encoder outputs on variable `encoder_states`.\n",
        "\n",
        "Store in the form of [__hiddenstate__, __contextstate__]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "deletable": false,
        "id": "i5U5W2T9f7Qk",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "63deee770ecdaabe4190ed7e5abe4859",
          "grade": false,
          "grade_id": "cell-5375e524cb9be57b",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "tags": [
          "Ex-4-Task-1"
        ]
      },
      "outputs": [],
      "source": [
        "### Ex-4-Task-1\n",
        "# encoder_states = None\n",
        "\n",
        "# Encoder Architecture\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.input_size = input_size\n",
        "\n",
        "        self.embedding_size = embedding_size\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(self.input_size, self.embedding_size)\n",
        "\n",
        "        self.LSTM = nn.LSTM(self.embedding_size, self.hidden_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedding = self.embedding(x)\n",
        "        outputs, (hidden_state, cell_state) = self.LSTM(embedding)\n",
        "        \n",
        "        ### BEGIN SOLUTION\n",
        "        encoder_states = [hidden_state, cell_state]\n",
        "        ### END SOLUTION\n",
        "        return encoder_states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "sk67U0fRx212",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2aa9b3af095f8429833dca9530395f81",
          "grade": true,
          "grade_id": "cell-71c476202d589f78",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": [
          "Ex-4-Task-1"
        ]
      },
      "outputs": [],
      "source": [
        "# Intentionally left blank"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "-miqEPX4f7Ql",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "78b937a268a0f394a91de96f76b3a5e9",
          "grade": false,
          "grade_id": "cell-ddac4c4be3f9b645",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "68ea3317-565f-4c03-cdf0-92db367c7280",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder(\n",
            "  (embedding): Embedding(3381, 50)\n",
            "  (LSTM): LSTM(50, 50)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "encoder = Encoder(num_encoder_tokens, latent_dim, latent_dim)\n",
        "print(encoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "jwgWEUvqf7Qm",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3763687430eae58b6cbbcb7e65d2c712",
          "grade": false,
          "grade_id": "cell-57a28a9db81414dd",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, output_size):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        # Size of the one hot vectors that will be the input to the decoder\n",
        "        self.input_size = input_size\n",
        "\n",
        "        # Output size of the word embedding NN\n",
        "        self.embedding_size = embedding_size\n",
        "\n",
        "        # Dimension of the NN's inside the lstm cell/ (hs,cs)'s dimension.\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # Size of the one hot vectors that will be the output of the decoder\n",
        "        self.output_size = output_size\n",
        "\n",
        "        self.embedding = nn.Embedding(self.input_size, self.embedding_size)\n",
        "        self.LSTM = nn.LSTM(self.embedding_size, hidden_size)\n",
        "        self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, x, enc_states):\n",
        "        x = x.unsqueeze(0)\n",
        "        embedding = self.embedding(x)\n",
        "\n",
        "        # (passing encoder's hs, cs - context vectors)\n",
        "        outputs, (hidden_state, cell_state) = self.LSTM(embedding, enc_states)\n",
        "\n",
        "        predictions = self.fc(outputs)\n",
        "\n",
        "        predictions = predictions.squeeze(0)\n",
        "\n",
        "        decoder_states = (hidden_state, cell_state)\n",
        "\n",
        "        return predictions, decoder_states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "zuqq79h6f7Qm",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f14fa8d3ff8a10b6287be85df6c77281",
          "grade": false,
          "grade_id": "cell-5f7f0bed03f209a8",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "f2c6bacb-c68a-4f74-83c0-c978a6e2c6ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder(\n",
            "  (embedding): Embedding(9024, 50)\n",
            "  (LSTM): LSTM(50, 50)\n",
            "  (fc): Linear(in_features=50, out_features=9024, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "decoder = Decoder(num_decoder_tokens, latent_dim, latent_dim, num_decoder_tokens)\n",
        "print(decoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "ycS6r5fkf7Qm",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "212805f25732ea0776a6ce3bd0a57458",
          "grade": false,
          "grade_id": "cell-c8fc9c2ef2ac84be",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, Encoder_LSTM, Decoder_LSTM):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.Encoder_LSTM = Encoder_LSTM\n",
        "        self.Decoder_LSTM = Decoder_LSTM\n",
        "\n",
        "    def forward(self, source, target, tfr=0.5):\n",
        "        batch_size = source.shape[1]\n",
        "\n",
        "        target_len = target.shape[0]\n",
        "        target_vocab_size = num_decoder_tokens\n",
        "\n",
        "        outputs = torch.zeros(target_len, batch_size, target_vocab_size)\n",
        "\n",
        "        hidden_state, cell_state = self.Encoder_LSTM(source)\n",
        "\n",
        "        x = target[0]\n",
        "\n",
        "        for i in range(1, target_len):\n",
        "            output, ( hidden_state, cell_state ) = self.Decoder_LSTM(x, (hidden_state, cell_state))\n",
        "            outputs[i] = output\n",
        "            best_guess = output.argmax(1) # 1st dimension is word embedding, 0th dimension is batchsize\n",
        "            x = target[i] if random.random() < tfr else best_guess # Either pass the next word correctly from the dataset or use the earlier predicted word\n",
        "\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "KxU_HH2mf7Qm",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "c324a3bc939ea45333ebc3d6435cbf34",
          "grade": false,
          "grade_id": "cell-61d8cb7f520b0326",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "\n",
        "learning_rate = 0.001\n",
        "step = 0\n",
        "\n",
        "model = Seq2Seq(encoder, decoder)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "xu-3m5qg0-G1",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "07abc23b4cedabba832b7e15d98d3fef",
          "grade": false,
          "grade_id": "cell-cdd4235d80801b39",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "#### Task 2\n",
        "<b><div style=\"text-align: right\">[POINTS: 3]</div></b>\n",
        "Increase the number of epochs and train the model to obtain a good accuracy score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "cymSsIYQw6Me",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "38a67eb038486a9db3fc03603d8b6ed6",
          "grade": false,
          "grade_id": "cell-d5ca1a01a0838cda",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# Some model hyperparameters\n",
        "train_samples = len(X_train)\n",
        "val_samples = len(X_test)\n",
        "batch_size = 256\n",
        "num_epochs = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "ZWX1460-zVv6",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1506343e4b40cdd6ca2faf2b9c5c3923",
          "grade": false,
          "grade_id": "cell-9fdc16b573193e9a",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "1308a16f-917e-4b61-9a29-deb6868fa752",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch - 1 / 2\n",
            "Iterations / loss -  0 / 9.173311233520508\n",
            "\n",
            "Iterations / loss -  1 / 9.128021240234375\n",
            "\n",
            "Iterations / loss -  2 / 9.090535163879395\n",
            "\n",
            "Iterations / loss -  3 / 9.054544448852539\n",
            "\n",
            "Iterations / loss -  4 / 9.006528854370117\n",
            "\n",
            "Iterations / loss -  5 / 8.992653846740723\n",
            "\n",
            "Iterations / loss -  6 / 8.948244094848633\n",
            "\n",
            "Iterations / loss -  7 / 8.897843360900879\n",
            "\n",
            "Iterations / loss -  8 / 8.802606582641602\n",
            "\n",
            "Iterations / loss -  9 / 8.774892807006836\n",
            "\n",
            "Iterations / loss -  10 / 8.698709487915039\n",
            "\n",
            "Iterations / loss -  11 / 8.598956108093262\n",
            "\n",
            "Iterations / loss -  12 / 8.498756408691406\n",
            "\n",
            "Iterations / loss -  13 / 8.436701774597168\n",
            "\n",
            "Iterations / loss -  14 / 8.305533409118652\n",
            "\n",
            "Iterations / loss -  15 / 8.200568199157715\n",
            "\n",
            "Iterations / loss -  16 / 8.083052635192871\n",
            "\n",
            "Iterations / loss -  17 / 7.951202869415283\n",
            "\n",
            "Iterations / loss -  18 / 7.825520992279053\n",
            "\n",
            "Iterations / loss -  19 / 7.684548854827881\n",
            "\n",
            "Iterations / loss -  20 / 7.552221298217773\n",
            "\n",
            "Iterations / loss -  21 / 7.389553070068359\n",
            "\n",
            "Iterations / loss -  22 / 7.226900577545166\n",
            "\n",
            "Iterations / loss -  23 / 7.0778021812438965\n",
            "\n",
            "Iterations / loss -  24 / 6.917173862457275\n",
            "\n",
            "Iterations / loss -  25 / 6.758057117462158\n",
            "\n",
            "Iterations / loss -  26 / 6.601959705352783\n",
            "\n",
            "Iterations / loss -  27 / 6.4158830642700195\n",
            "\n",
            "Iterations / loss -  28 / 6.252442836761475\n",
            "\n",
            "Iterations / loss -  29 / 6.092087268829346\n",
            "\n",
            "Iterations / loss -  30 / 5.897215366363525\n",
            "\n",
            "Iterations / loss -  31 / 5.76270866394043\n",
            "\n",
            "Iterations / loss -  32 / 5.565150737762451\n",
            "\n",
            "Iterations / loss -  33 / 5.415520191192627\n",
            "\n",
            "Iterations / loss -  34 / 5.221888065338135\n",
            "\n",
            "Iterations / loss -  35 / 4.813318252563477\n",
            "\n",
            "Epoch - 2 / 2\n",
            "Iterations / loss -  0 / 4.877805233001709\n",
            "\n",
            "Iterations / loss -  1 / 4.698530673980713\n",
            "\n",
            "Iterations / loss -  2 / 4.560123920440674\n",
            "\n",
            "Iterations / loss -  3 / 4.415103912353516\n",
            "\n",
            "Iterations / loss -  4 / 4.235677242279053\n",
            "\n",
            "Iterations / loss -  5 / 4.034219264984131\n",
            "\n",
            "Iterations / loss -  6 / 3.910006046295166\n",
            "\n",
            "Iterations / loss -  7 / 3.766195058822632\n",
            "\n",
            "Iterations / loss -  8 / 3.5608015060424805\n",
            "\n",
            "Iterations / loss -  9 / 3.4544339179992676\n",
            "\n",
            "Iterations / loss -  10 / 3.3015339374542236\n",
            "\n",
            "Iterations / loss -  11 / 3.156162977218628\n",
            "\n",
            "Iterations / loss -  12 / 2.974315643310547\n",
            "\n",
            "Iterations / loss -  13 / 2.8355886936187744\n",
            "\n",
            "Iterations / loss -  14 / 2.7257227897644043\n",
            "\n",
            "Iterations / loss -  15 / 2.5751805305480957\n",
            "\n",
            "Iterations / loss -  16 / 2.4384989738464355\n",
            "\n",
            "Iterations / loss -  17 / 2.3090696334838867\n",
            "\n",
            "Iterations / loss -  18 / 2.1857454776763916\n",
            "\n",
            "Iterations / loss -  19 / 2.076470136642456\n",
            "\n",
            "Iterations / loss -  20 / 1.9706491231918335\n",
            "\n",
            "Iterations / loss -  21 / 1.8365797996520996\n",
            "\n",
            "Iterations / loss -  22 / 1.732912540435791\n",
            "\n",
            "Iterations / loss -  23 / 1.6364719867706299\n",
            "\n",
            "Iterations / loss -  24 / 1.5303583145141602\n",
            "\n",
            "Iterations / loss -  25 / 1.4560160636901855\n",
            "\n",
            "Iterations / loss -  26 / 1.3547205924987793\n",
            "\n",
            "Iterations / loss -  27 / 1.2712671756744385\n",
            "\n",
            "Iterations / loss -  28 / 1.186342716217041\n",
            "\n",
            "Iterations / loss -  29 / 1.1126106977462769\n",
            "\n",
            "Iterations / loss -  30 / 1.0426644086837769\n",
            "\n",
            "Iterations / loss -  31 / 0.9892795085906982\n",
            "\n",
            "Iterations / loss -  32 / 0.91866534948349\n",
            "\n",
            "Iterations / loss -  33 / 0.8642469644546509\n",
            "\n",
            "Iterations / loss -  34 / 0.8163589239120483\n",
            "\n",
            "Iterations / loss -  35 / 1.0888395309448242\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Training the model\n",
        "epoch_loss = 0.0\n",
        "best_loss = 999999\n",
        "losses = []\n",
        "best_epoch = -1\n",
        "ts1  = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_loss_list = []\n",
        "    print(\"Epoch - {} / {}\".format(epoch+1, num_epochs))\n",
        "    \n",
        "\n",
        "    model.train(True)\n",
        "    for batch_idx, ( input_data, target_data ) in enumerate(generate_batch(batch_size=batch_size)):\n",
        "        input_data_enc = torch.tensor(input_data[0]).long()\n",
        "        input_data_dec = torch.tensor(input_data[1]).long()\n",
        "        target = torch.tensor(target_data.argmax(2)).long()\n",
        "        \n",
        "        # Pass the input and target for model's forward method\n",
        "        output = model(input_data_enc, target)\n",
        "        output = output[1:].reshape(-1, output.shape[2])\n",
        "        target = target[1:].reshape(-1)\n",
        "\n",
        "        # Clear the accumulating gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Calculate the loss value for every epoch\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # Calculate the gradients for weights & biases using back-propagation\n",
        "        loss.backward()\n",
        "\n",
        "        # Update the weights values using the gradients we calculated using bp \n",
        "        optimizer.step()\n",
        "        step += 1\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        epoch_loss_list.append(loss.item())\n",
        "\n",
        "        if epoch_loss < best_loss:\n",
        "            best_loss = epoch_loss\n",
        "            best_epoch = epoch\n",
        "        if ((epoch - best_epoch) >= 10):\n",
        "            print(\"no improvement in 10 epochs, break\")\n",
        "            break\n",
        "        print(\"Iterations / loss -  {} / {}\".format(batch_idx,loss.item()))\n",
        "        print()\n",
        "    losses.append(np.mean(epoch_loss_list))\n",
        "\n",
        "torch.save({\n",
        "          'model_state_dict': model.state_dict(),\n",
        "          'loss': losses\n",
        "          },\"lstm_seq2seq\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "deletable": false,
        "id": "K1kgspYr0-G1",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a606c7517aefd327f82ecdc8c1e0c180",
          "grade": false,
          "grade_id": "cell-404e9c0d68a46c7c",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "tags": [
          "Ex-4-Task-2"
        ]
      },
      "outputs": [],
      "source": [
        "### Ex-4-Task-2\n",
        "loss = None\n",
        "\n",
        "# Model Loss\n",
        "# Store the model's loss from trained above\n",
        "\n",
        "# Exercise 4 | Task 2\n",
        "### BEGIN SOLUTION\n",
        "# loss = torch.mean(torch.Tensor(losses))\n",
        "loss = losses\n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "AUJwO-z2LORt",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "fe4b6e1a7da659d7d7bb61358f49fe84",
          "grade": false,
          "grade_id": "cell-cd972e8c828f74d6",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "c5a59f4a-fb10-495a-956e-ed7f35397e36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5.0279)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "rcMS1UgA0-G1",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "7f502d775a57040c58d4ee2ec8f3023d",
          "grade": true,
          "grade_id": "cell-2c02ab4a9929d13a",
          "locked": true,
          "points": 3,
          "schema_version": 3,
          "solution": false
        },
        "tags": [
          "Ex-4-Task-2"
        ]
      },
      "outputs": [],
      "source": [
        "#INTENTIONALLY LEFT BLANK\n",
        "assert loss is not None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "h50t4Y7f0-G1",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "d560f9d70599bdd447567969c6bb2f08",
          "grade": false,
          "grade_id": "cell-8989e398a4400b6e",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Now, after we performed some preprocessing and model training steps, then we will start working on the model inferencing. We will see how well the model predicts the results. Also, we will discover what can be the possible solution to this problem.\n",
        "\n",
        "If we look at the model training results, we can see that the model is not performing really well. This may be because the LSTM network we are using is not able to learn the appropriate feature inputs. The no. of tokens is also pretty large which is giving the model a hard time to learn the input feature itself. So, the possible solution to these problems could be the `Attention Mechanisms`. We have not used attention mechanism, however if we use attention mechanism the result will surely turn out better.\n",
        "\n",
        "Moreover, we can validate the performance of the model by also inferencing on the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "vm-p0L85w6Mi",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "8c8a39c7744b369949a86787e8834f7f",
          "grade": false,
          "grade_id": "cell-c942df3936e27c26",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "###  Decode Sample Sequences\n",
        "\n",
        "Following is the code to decode the input sequence to the machine translation network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "SEf9I1brw6Mi",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "5a0b45c69b73e5f81bf61c8626dadf94",
          "grade": false,
          "grade_id": "cell-5ed91b4ae4003424",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "model = Seq2Seq(Encoder(num_encoder_tokens, latent_dim, latent_dim), Decoder(num_decoder_tokens, latent_dim, latent_dim, num_decoder_tokens))\n",
        "\n",
        "\n",
        "checkpoint = torch.load(\"lstm_seq2seq\")\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "def decode_sequence(sentence, max_length=50):\n",
        "    model.eval()\n",
        "    # lower, removing punctuations, \n",
        "    tokens =  (''.join(char for char in re.sub(\" +\", \" \", re.sub(\"'\", '', sentence).lower()) if char not in sets_of_punctuations)).split()\n",
        "\n",
        "    text_to_indices = [ input_token_index[token] for token in tokens]\n",
        "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1)\n",
        "\n",
        "    # Build encoder hidden, cell state\n",
        "    with torch.no_grad():\n",
        "        hidden, cell = model.Encoder_LSTM(sentence_tensor)\n",
        "\n",
        "    outputs = [target_token_index[\"<START>\"]]\n",
        "\n",
        "    for _ in range(max_length):\n",
        "        previous_word = torch.LongTensor([outputs[-1]])\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output, ( hidden, cell ) = model.Decoder_LSTM(previous_word, (hidden, cell))\n",
        "            best_guess = output.argmax(1).item()\n",
        "\n",
        "        outputs.append(best_guess)\n",
        "\n",
        "        # Model predicts it's the end of the sentence\n",
        "        if best_guess == \"<END>\":\n",
        "            break\n",
        "\n",
        "    translated_sentence = [reverse_target_char_index.get(idx, '<PAD>') for idx in outputs]\n",
        "    return translated_sentence[1:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "nlUCxJsnw6Mj",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "763c22c34ded6325c5ad21a2a9355592",
          "grade": false,
          "grade_id": "cell-c83a2b40557db068",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Evaluation on Train Dataset\n",
        "\n",
        "Generating the sample to check some of the results predicted by the machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "C_pmnLSGw6Mk",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "62ea65b73b7feb701332ebb26bccf2e2",
          "grade": false,
          "grade_id": "cell-5ecd5fc414a45548",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "2a6209d7-9f0d-4049-c878-e847954ebafc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input English sentence: welcome to our home\n",
            "Actual Chinese Translation: <START> 欢迎来到我们家。 <END>\n",
            "Predicted Chinese Translation: ['<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"
          ]
        }
      ],
      "source": [
        "k=0\n",
        "decoded_sentence = decode_sequence(X_train[k:k+1].values[0])\n",
        "print('Input English sentence:', X_train[k:k+1].values[0])\n",
        "print('Actual Chinese Translation:', y_train[k:k+1].values[0])\n",
        "print('Predicted Chinese Translation:', decoded_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "t9-tBDjSw6Mk",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2cb0841aa20be247dc2cfa65c9ff8f81",
          "grade": false,
          "grade_id": "cell-ed8c1f20e44cf9ea",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "84bb99bd-1ea9-4317-95b7-fa97d312d058",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input English sentence: he was made captain\n",
            "Actual Chinese Translation: <START> 他被選為隊長。 <END>\n",
            "Predicted Chinese Translation: ['<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"
          ]
        }
      ],
      "source": [
        "k+=1\n",
        "decoded_sentence = decode_sequence(X_train[k:k+1].values[0])\n",
        "print('Input English sentence:', X_train[k:k+1].values[0])\n",
        "print('Actual Chinese Translation:', y_train[k:k+1].values[0])\n",
        "print('Predicted Chinese Translation:', decoded_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "3TZxb_9Yw6Ml",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b5fa51f0d95647f9eabb3536d3f3ffc8",
          "grade": false,
          "grade_id": "cell-415bd9a5589e425e",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "62a86584-19e9-4364-806e-1cbc8356bf38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input English sentence: the soup is thick\n",
            "Actual Chinese Translation: <START> 汤很稠。 <END>\n",
            "Predicted Chinese Translation: ['<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"
          ]
        }
      ],
      "source": [
        "k+=1\n",
        "decoded_sentence = decode_sequence(X_train[k:k+1].values[0])\n",
        "print('Input English sentence:', X_train[k:k+1].values[0])\n",
        "print('Actual Chinese Translation:', y_train[k:k+1].values[0])\n",
        "print('Predicted Chinese Translation:', decoded_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "udM3JsI9w6Ml",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1e0a03d70e00916d5e4b79b1f091cb4e",
          "grade": false,
          "grade_id": "cell-7fcb2d3381bba963",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "0e4d88fd-24f1-4fc9-c8ec-9e5ea43ccee7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input English sentence: dont kid around\n",
            "Actual Chinese Translation: <START> 別開玩笑了。 <END>\n",
            "Predicted Chinese Translation: ['<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"
          ]
        }
      ],
      "source": [
        "k+=1\n",
        "decoded_sentence = decode_sequence(X_train[k:k+1].values[0])\n",
        "print('Input English sentence:', X_train[k:k+1].values[0])\n",
        "print('Actual Chinese Translation:', y_train[k:k+1].values[0])\n",
        "print('Predicted Chinese Translation:', decoded_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "dCL7Qdt5w6Mm",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f36cbe941bac7f99dbc50e5e80d1c331",
          "grade": false,
          "grade_id": "cell-5e36305a19daeb11",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "40ccb689-ae35-428e-c10f-d8e9f4667097",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input English sentence: flowers bloom\n",
            "Actual Chinese Translation: <START> 鮮花盛開。 <END>\n",
            "Predicted Chinese Translation: ['她说了她很幸福。', '这很难。', '我們為甚麼失敗了？', '<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"
          ]
        }
      ],
      "source": [
        "k+=1\n",
        "decoded_sentence = decode_sequence(X_train[k:k+1].values[0])\n",
        "print('Input English sentence:', X_train[k:k+1].values[0])\n",
        "print('Actual Chinese Translation:', y_train[k:k+1].values[0])\n",
        "print('Predicted Chinese Translation:', decoded_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "lnRsCWcGv-B9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "eGmUTVPS0-G3",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "4482e01ff125db80d9d6e06049834443",
          "grade": false,
          "grade_id": "cell-b60c247b0c3f991f",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "CONGRATULATIONS!!! on completing the Assignment."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JxEm638DFm7P"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}